<!DOCTYPE html>
<html>
<head>
<style>
  h1, p {
    font-family: system-ui;
    font-weight: 300;
  }
</style>
<title>AI/ML you need - SourceLab</title>
</head>
<body>
<h1>SourceLab</h1>
<p>SourceLab offers a great way for AI to help you, and the world.</p>
<p>Atom AI</p>
<a href="https://github.com/electric-otter/atomai/releases/tag/v1.0.0">Try Atom AI</a>
<p>Or in the web!</p>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
    <script src="tfjs_model/model.json"></script>
  <script>
    async function setupCamera() {
    const video = document.getElementById('video');
    const stream = await navigator.mediaDevices.getUserMedia({
        video: true,
    });
    video.srcObject = stream;
    return new Promise((resolve) => {
        video.onloadedmetadata = () => {
            resolve(video);
        };
    });
}

async function loadModel() {
    const model = await tf.loadLayersModel('tfjs_model/model.json');
    return model;
}

function getEmotionColor(emotion) {
    const colors = {
        'Angry': 'rgba(255, 0, 0, 0.5)',
        'Disgust': 'rgba(0, 255, 0, 0.5)',
        'Fear': 'rgba(255, 255, 0, 0.5)',
        'Happy': 'rgba(0, 255, 255, 0.5)',
        'Sad': 'rgba(0, 0, 255, 0.5)',
        'Surprise': 'rgba(255, 0, 255, 0.5)',
        'Neutral': 'rgba(255, 255, 255, 0.5)',
    };
    return colors[emotion] || 'rgba(255, 255, 255, 0.5)';
}

async function predictEmotion(model, video) {
    const canvas = document.createElement('canvas');
    canvas.width = video.width;
    canvas.height = video.height;
    const ctx = canvas.getContext('2d');

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

    const img = tf.browser.fromPixels(imageData).resizeNearestNeighbor([48, 48]).mean(2).expandDims(2).expandDims(0).toFloat().div(255);

    const prediction = model.predict(img);
    const emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'];
    const emotion = emotions[tf.argMax(prediction, 1).dataSync()[0]];

    ctx.fillStyle = getEmotionColor(emotion);
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    return ctx.canvas.toDataURL('image/png');
}

async function main() {
    const video = await setupCamera();
    const model = await loadModel();
    video.play();

    const canvas = document.createElement('canvas');
    canvas.width = video.width;
    canvas.height = video.height;
    document.body.appendChild(canvas);
    const ctx = canvas.getContext('2d');

    async function detect() {
        const emotionImage = await predictEmotion(model, video);
        const img = new Image();
        img.src = emotionImage;
        img.onload = () => {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
        };
        requestAnimationFrame(detect);
    }

    detect();
}

main();

  </script>
</body>
</html>
